{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from string import Template\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = '/kaggle/input/flan-t5/pytorch/xl/3'\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(llm, device_map=\"auto\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(llm)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def query_model_batch(premessage, batch_prompts):\n",
    "    responses = []\n",
    "    for prompt in batch_prompts:\n",
    "        responses.append(generate(premessage + prompt))\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset:\n",
    "    def __init__(self, prompts, answers):\n",
    "        self.prompts = prompts\n",
    "        self.answers = answers\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prompts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"prompt\": self.prompts[idx], \"answer\": self.answers[idx]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premessage = \"\"\"\n",
    "You have to answer complex questions based on the provided contexts.\n",
    "Respond with as few tokens as possible. You don't need to explain your answer. \n",
    "Don't add any extra information.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def read_json(file_path: str) -> dict:\n",
    "    \"\"\"Read a json file and return a dict.\"\"\"\n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "oracle = read_json('/kaggle/input/d/thanosgeorgoutsos/rag-retrieve-responses/oracle.json')\n",
    "oracle_random = read_json('/kaggle/input/d/thanosgeorgoutsos/rag-retrieve-responses/oracle_random_3.json')\n",
    "oracle_adore = read_json('/kaggle/input/d/thanosgeorgoutsos/rag-retrieve-responses/oracle_adore_3.json')\n",
    "top3 = read_json('/kaggle/input/d/thanosgeorgoutsos/rag-retrieve-responses/top3_3.json')\n",
    "top3_random = read_json('/kaggle/input/d/thanosgeorgoutsos/rag-retrieve-responses/top3_random_3.json')\n",
    "top3_adore = read_json('/kaggle/input/d/thanosgeorgoutsos/rag-retrieve-responses/top3_adore_3.json')\n",
    "response = read_json('/kaggle/input/r-and-h/random_contexts.json')\n",
    "corpus = read_json('/kaggle/input/wiki-data/wiki_musique_corpus.json')\n",
    "dev = read_json('/kaggle/input/wiki-data/dev.json')[:1200]\n",
    "\n",
    "# faster way to index the data\n",
    "dev_df = pd.DataFrame(dev)\n",
    "dev_df.set_index('_id', inplace=True)\n",
    "\n",
    "def get_ground_truth(idx, supporting_facts=False):\n",
    "    \"\"\"\n",
    "    Extract the question, oracle contexts and answer from dev.\n",
    "    The oracle contexts are tuples (title, text).\n",
    "    \"\"\"\n",
    "    row = dev_df.loc[idx]\n",
    "    if supporting_facts:\n",
    "        sfs = [t for t, _ in row['supporting_facts']]\n",
    "        oracle = [(title, ' '.join(texts)) for title, texts in row['context'] if title in sfs]\n",
    "    else:\n",
    "        oracle = [(title, ' '.join(texts)) for title, texts in row['context']]\n",
    "    return row['question'], oracle, row['answer']\n",
    "\n",
    "def get_top_k_contexts(responses, k=5):\n",
    "    \"\"\"Extract the top k similar contexts from the corpus. Each\n",
    "    context is a tuple (title, text).\n",
    "    \"\"\"\n",
    "    top_k_contexts = []\n",
    "    for i, (idx, score) in enumerate(responses.items()):\n",
    "        if i < k:\n",
    "            tittle = corpus[idx]['title']\n",
    "            text = corpus[idx]['text']\n",
    "            top_k_contexts.append((tittle, text))\n",
    "    return top_k_contexts\n",
    "\n",
    "def create_prompt(contexts, question):\n",
    "    \"\"\"Create a prompt for the model.\"\"\"\n",
    "    prompt = \"Documents:\\n\"\n",
    "    for i, (title, text) in enumerate(contexts):\n",
    "        prompt += f\"Document[{i+1}](Title: {title}) {text}\\n\"\n",
    "    prompt += f\"\\nQuestion: {question}\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_list = []\n",
    "questions = []\n",
    "for _id, similar_ctx_ids in oracle.items():\n",
    "    question, oracle_ctxs, answer = get_ground_truth(_id, supporting_facts=True)\n",
    "    questions.append(question)\n",
    "    \n",
    "    prompt_oracle =  premessage +similar_ctx_ids['prompt']\n",
    "    \n",
    "    # save prompts in a list\n",
    "    oracle_list.append({\n",
    "        \"prompt_oracle\": prompt_oracle,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "\n",
    "# save results in json file with nice indentation\n",
    "with open('/kaggle/working/prompts_oracle.json', 'w') as f:\n",
    "    json.dump(oracle_list, f, indent=4)\n",
    "    \n",
    "prompts_oracle = [oracle_list[i]['prompt_oracle'] for i in range(len(oracle_list[:100]))]\n",
    "answers = [oracle_list[i]['answer'] for i in range(len(oracle_list))]\n",
    "\n",
    "oracle_random_list = []\n",
    "for _id, similar_ctx_ids in oracle_random.items():\n",
    "    question, oracle_ctxs, answer = get_ground_truth(_id, supporting_facts=True)\n",
    "    \n",
    "    prompt_oracle =  premessage +similar_ctx_ids['prompt']\n",
    "    \n",
    "    # save prompts in a list\n",
    "    oracle_random_list.append({\n",
    "        \"prompt_oracle_random\": prompt_oracle,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "\n",
    "# save results in json file with nice indentation\n",
    "with open('/kaggle/working/prompts_oracle_random.json', 'w') as f:\n",
    "    json.dump(oracle_random_list, f, indent=4)\n",
    "    \n",
    "prompts_oracle_random = [oracle_random_list[i]['prompt_oracle_random'] for i in range(len(oracle_random_list[:100]))]\n",
    "\n",
    "oracle_adore_list = []\n",
    "for _id, similar_ctx_ids in oracle_adore.items():\n",
    "    question, oracle_ctxs, answer = get_ground_truth(_id, supporting_facts=True)\n",
    "    \n",
    "    prompt_oracle =  premessage +similar_ctx_ids['prompt']\n",
    "    \n",
    "    # save prompts in a list\n",
    "    oracle_adore_list.append({\n",
    "        \"prompt_oracle_adore\": prompt_oracle,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "\n",
    "# save results in json file with nice indentation\n",
    "with open('/kaggle/working/prompts_oracle_adore.json', 'w') as f:\n",
    "    json.dump(oracle_adore_list, f, indent=4)\n",
    "    \n",
    "prompts_oracle_adore = [oracle_adore_list[i]['prompt_oracle_adore'] for i in range(len(oracle_adore_list[:100]))]\n",
    "\n",
    "top3_list = []\n",
    "for _id, similar_ctx_ids in top3.items():\n",
    "    question, oracle_ctxs, answer = get_ground_truth(_id, supporting_facts=True)\n",
    "    \n",
    "    prompt_oracle =  premessage +similar_ctx_ids['prompt']\n",
    "    \n",
    "    # save prompts in a list\n",
    "    top3_list.append({\n",
    "        \"prompt_top3\": prompt_oracle,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "\n",
    "# save results in json file with nice indentation\n",
    "with open('/kaggle/working/prompts_top3.json', 'w') as f:\n",
    "    json.dump(top3_list, f, indent=4)\n",
    "    \n",
    "prompts_top3 = [top3_list[i]['prompt_top3'] for i in range(len(top3_list[:100]))]\n",
    "\n",
    "top3_random_list = []\n",
    "for _id, similar_ctx_ids in top3_random.items():\n",
    "    question, oracle_ctxs, answer = get_ground_truth(_id, supporting_facts=True)\n",
    "    \n",
    "    prompt_oracle =  premessage +similar_ctx_ids['prompt']\n",
    "    \n",
    "    # save prompts in a list\n",
    "    top3_random_list.append({\n",
    "        \"prompt_top3_random\": prompt_oracle,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "\n",
    "# save results in json file with nice indentation\n",
    "with open('/kaggle/working/prompts_top3_random.json', 'w') as f:\n",
    "    json.dump(top3_random_list, f, indent=4)\n",
    "    \n",
    "prompts_top3_random = [top3_random_list[i]['prompt_top3_random'] for i in range(len(top3_random_list[:100]))]\n",
    "\n",
    "top3_adore_list = []\n",
    "for _id, similar_ctx_ids in top3_adore.items():\n",
    "    question, oracle_ctxs, answer = get_ground_truth(_id, supporting_facts=True)\n",
    "    \n",
    "    prompt_oracle =  premessage +similar_ctx_ids['prompt']\n",
    "    \n",
    "    # save prompts in a list\n",
    "    top3_adore_list.append({\n",
    "        \"prompt_top3_adore\": prompt_oracle,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "\n",
    "# save results in json file with nice indentation\n",
    "with open('/kaggle/working/prompts_top3_adore.json', 'w') as f:\n",
    "    json.dump(top3_adore_list, f, indent=4)\n",
    "    \n",
    "prompts_top3_adore = [top3_adore_list[i]['prompt_top3_adore'] for i in range(len(top3_adore_list[:100]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['oracle', 'oracle_random', 'oracle_adore', 'top3', 'top3_random', 'top3_adore']\n",
    "prs = [prompts_oracle, prompts_oracle_random, prompts_oracle_adore, prompts_top3, prompts_top3_random, prompts_top3_adore]\n",
    "\n",
    "for j, p in enumerate(prs): \n",
    "    dataset = CustomDataset(p, answers)\n",
    "    top5_dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    dictionary = {}\n",
    "    counter = 0\n",
    "\n",
    "    for batch in top5_dataloader:\n",
    "        batch_prompts = batch['prompt']\n",
    "        batch_answers = batch['answer']\n",
    "        responses = query_model_batch(premessage, batch_prompts)\n",
    "        counter += len(batch_prompts)\n",
    "        print(counter)\n",
    "\n",
    "        for i in range(len(responses)):\n",
    "\n",
    "            response = responses[i][0]\n",
    "            answer = batch_answers[i]\n",
    "#             print(response, answer)\n",
    "            dictionary[batch_prompts[i]] = [response, answer]\n",
    "\n",
    "\n",
    "    with open(f'/kaggle/working/{titles[j]}.json', 'w') as f:\n",
    "        json.dump(dictionary, f, indent=4)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
