{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751abc66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T17:02:51.405235Z",
     "iopub.status.busy": "2024-05-31T17:02:51.404886Z",
     "iopub.status.idle": "2024-05-31T17:03:13.009884Z",
     "shell.execute_reply": "2024-05-31T17:03:13.008857Z"
    },
    "papermill": {
     "duration": 21.612666,
     "end_time": "2024-05-31T17:03:13.012254",
     "exception": false,
     "start_time": "2024-05-31T17:02:51.399588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.1)\r\n",
      "Collecting faiss-gpu\r\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.15.1)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (1.26.100)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.4.0)\r\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.59.3)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.26.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.5.2)\r\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (69.0.3)\r\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.16.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.0.3)\r\n",
      "Collecting botocore<1.30.0,>=1.29.100 (from boto3)\r\n",
      "  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3) (0.6.2)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3) (2.9.0.post0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3) (1.26.18)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\r\n",
      "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: faiss-gpu, botocore\r\n",
      "  Attempting uninstall: botocore\r\n",
      "    Found existing installation: botocore 1.34.106\r\n",
      "    Uninstalling botocore-1.34.106:\r\n",
      "      Successfully uninstalled botocore-1.34.106\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "aiobotocore 2.13.0 requires aiohttp<4.0.0,>=3.9.2, which is not installed.\r\n",
      "s3fs 2024.3.1 requires aiohttp!=4.0.0a0,!=4.0.0a1, which is not installed.\r\n",
      "aiobotocore 2.13.0 requires botocore<1.34.107,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed botocore-1.29.165 faiss-gpu-1.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers faiss-gpu tensorboard boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85deb034",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T17:03:13.029413Z",
     "iopub.status.busy": "2024-05-31T17:03:13.029089Z",
     "iopub.status.idle": "2024-05-31T17:03:18.734842Z",
     "shell.execute_reply": "2024-05-31T17:03:18.733857Z"
    },
    "papermill": {
     "duration": 5.71744,
     "end_time": "2024-05-31T17:03:18.737578",
     "exception": false,
     "start_time": "2024-05-31T17:03:13.020138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import enum\n",
    "import sys\n",
    "\n",
    "from torch._C import dtype\n",
    "sys.path += ['./']\n",
    "import torch\n",
    "from torch import nn\n",
    "import transformers\n",
    "if int(transformers.__version__[0]) <=3:\n",
    "    from transformers.modeling_roberta import RobertaPreTrainedModel\n",
    "else:\n",
    "    from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "from transformers import RobertaModel\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "\n",
    "class EmbeddingMixin:\n",
    "    \"\"\"\n",
    "    Mixin for common functions in most embedding models. Each model should define its own bert-like backbone and forward.\n",
    "    We inherit from RobertaModel to use from_pretrained \n",
    "    \"\"\"\n",
    "    def __init__(self, model_argobj):\n",
    "        if model_argobj is None:\n",
    "            self.use_mean = False\n",
    "        else:\n",
    "            self.use_mean = model_argobj.use_mean\n",
    "        print(\"Using mean:\", self.use_mean)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding, nn.Conv1d)):\n",
    "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
    "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "\n",
    "    def masked_mean(self, t, mask):\n",
    "        s = torch.sum(t * mask.unsqueeze(-1).float(), axis=1)\n",
    "        d = mask.sum(axis=1, keepdim=True).float()\n",
    "        return s / d\n",
    "\n",
    "    def masked_mean_or_first(self, emb_all, mask):\n",
    "        # emb_all is a tuple from bert - sequence output, pooler\n",
    "        assert isinstance(emb_all, tuple)\n",
    "        if self.use_mean:\n",
    "            return self.masked_mean(emb_all[0], mask)\n",
    "        else:\n",
    "            return emb_all[0][:, 0]\n",
    "\n",
    "    def query_emb(self, input_ids, attention_mask):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "    def body_emb(self, input_ids, attention_mask):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "\n",
    "class BaseModelDot(EmbeddingMixin):\n",
    "    def _text_encode(self, input_ids, attention_mask):\n",
    "        # TODO should raise NotImplementedError\n",
    "        # temporarily do this  \n",
    "        return None \n",
    "\n",
    "    def query_emb(self, input_ids, attention_mask):\n",
    "        outputs1 = self._text_encode(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "        full_emb = self.masked_mean_or_first(outputs1, attention_mask)\n",
    "        query1 = self.norm(self.embeddingHead(full_emb))\n",
    "        return query1\n",
    "\n",
    "    def body_emb(self, input_ids, attention_mask):\n",
    "        return self.query_emb(input_ids, attention_mask)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, is_query, *args):\n",
    "        assert len(args) == 0\n",
    "        if is_query:\n",
    "            return self.query_emb(input_ids, attention_mask)\n",
    "        else:\n",
    "            return self.body_emb(input_ids, attention_mask)\n",
    "\n",
    "\n",
    "class RobertaDot(BaseModelDot, RobertaPreTrainedModel):\n",
    "    def __init__(self, config, model_argobj=None):\n",
    "        BaseModelDot.__init__(self, model_argobj)\n",
    "        RobertaPreTrainedModel.__init__(self, config)\n",
    "        if int(transformers.__version__[0]) ==4 :\n",
    "            config.return_dict = False\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        if hasattr(config, \"output_embedding_size\"):\n",
    "            self.output_embedding_size = config.output_embedding_size\n",
    "        else:\n",
    "            self.output_embedding_size = config.hidden_size\n",
    "        print(\"output_embedding_size\", self.output_embedding_size)\n",
    "        self.embeddingHead = nn.Linear(config.hidden_size, self.output_embedding_size)\n",
    "        self.norm = nn.LayerNorm(self.output_embedding_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _text_encode(self, input_ids, attention_mask):\n",
    "        outputs1 = self.roberta(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "        return outputs1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee914799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T17:03:18.756726Z",
     "iopub.status.busy": "2024-05-31T17:03:18.756277Z",
     "iopub.status.idle": "2024-05-31T17:03:18.804406Z",
     "shell.execute_reply": "2024-05-31T17:03:18.803547Z"
    },
    "papermill": {
     "duration": 0.060303,
     "end_time": "2024-05-31T17:03:18.806395",
     "exception": false,
     "start_time": "2024-05-31T17:03:18.746092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += [\"./\"]\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset\n",
    "from typing import List\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class TextTokenIdsCache:\n",
    "    def __init__(self, data_dir, prefix):\n",
    "        meta = json.load(open(f\"{data_dir}/{prefix}_meta\"))\n",
    "        self.total_number = meta['total_number']\n",
    "        self.max_seq_len = meta['embedding_size']\n",
    "        try:\n",
    "            self.ids_arr = np.memmap(f\"{data_dir}/{prefix}.memmap\", \n",
    "                shape=(self.total_number, self.max_seq_len), \n",
    "                dtype=np.dtype(meta['type']), mode=\"r\")\n",
    "            self.lengths_arr = np.load(f\"{data_dir}/{prefix}_length.npy\")\n",
    "        except FileNotFoundError:\n",
    "            self.ids_arr = np.memmap(f\"{data_dir}/memmap/{prefix}.memmap\", \n",
    "                shape=(self.total_number, self.max_seq_len), \n",
    "                dtype=np.dtype(meta['type']), mode=\"r\")\n",
    "            self.lengths_arr = np.load(f\"{data_dir}/memmap/{prefix}_length.npy\")\n",
    "        assert len(self.lengths_arr) == self.total_number\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.total_number\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return self.ids_arr[item, :self.lengths_arr[item]]\n",
    "\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, ids_cache, max_seq_length):\n",
    "        self.ids_cache = ids_cache\n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "    def __len__(self):  \n",
    "        return len(self.ids_cache)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        input_ids = self.ids_cache[item].tolist()\n",
    "        seq_length = min(self.max_seq_length-1, len(input_ids)-1)\n",
    "        input_ids = [input_ids[0]] + input_ids[1:seq_length] + [input_ids[-1]]\n",
    "        attention_mask = [1]*len(input_ids)\n",
    "\n",
    "        ret_val = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"id\": item,\n",
    "        }\n",
    "        return ret_val\n",
    "\n",
    "\n",
    "class SubsetSeqDataset:\n",
    "    def __init__(self, subset: List[int], ids_cache, max_seq_length):\n",
    "        self.subset = sorted(list(subset))\n",
    "        self.alldataset = SequenceDataset(ids_cache, max_seq_length)\n",
    "        \n",
    "    def __len__(self):  \n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.alldataset[self.subset[item]]\n",
    "\n",
    "\n",
    "def load_rel(rel_path):\n",
    "    reldict = defaultdict(list)\n",
    "    for line in tqdm(open(rel_path), desc=os.path.split(rel_path)[1]):\n",
    "        qid, _, pid, _ = line.split()\n",
    "        qid, pid = int(qid), int(pid)\n",
    "        reldict[qid].append((pid))\n",
    "    return dict(reldict)\n",
    "    \n",
    "\n",
    "def load_rank(rank_path):\n",
    "    rankdict = defaultdict(list)\n",
    "    for line in tqdm(open(rank_path), desc=os.path.split(rank_path)[1]):\n",
    "        qid, pid, _ = line.split()\n",
    "        qid, pid = int(qid), int(pid)\n",
    "        rankdict[qid].append(pid)\n",
    "    return dict(rankdict)\n",
    "\n",
    "\n",
    "def pack_tensor_2D(lstlst, default, dtype, length=None):\n",
    "    batch_size = len(lstlst)\n",
    "    length = length if length is not None else max(len(l) for l in lstlst)\n",
    "    tensor = default * torch.ones((batch_size, length), dtype=dtype)\n",
    "    for i, l in enumerate(lstlst):\n",
    "        tensor[i, :len(l)] = torch.tensor(l, dtype=dtype)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def get_collate_function(max_seq_length):\n",
    "    cnt = 0\n",
    "    def collate_function(batch):\n",
    "        nonlocal cnt\n",
    "        length = None\n",
    "        if cnt < 10:\n",
    "            length = max_seq_length\n",
    "            cnt += 1\n",
    "\n",
    "        input_ids = [x[\"input_ids\"] for x in batch]\n",
    "        attention_mask = [x[\"attention_mask\"] for x in batch]\n",
    "        data = {\n",
    "            \"input_ids\": pack_tensor_2D(input_ids, default=1, \n",
    "                dtype=torch.int64, length=length),\n",
    "            \"attention_mask\": pack_tensor_2D(attention_mask, default=0, \n",
    "                dtype=torch.int64, length=length),\n",
    "        }\n",
    "        ids = [x['id'] for x in batch]\n",
    "        return data, ids\n",
    "    return collate_function  \n",
    "\n",
    "\n",
    "\n",
    "class TrainInbatchDataset(Dataset):\n",
    "    def __init__(self, rel_file, queryids_cache, docids_cache, \n",
    "            max_query_length, max_doc_length):\n",
    "        self.query_dataset = SequenceDataset(queryids_cache, max_query_length)\n",
    "        self.doc_dataset = SequenceDataset(docids_cache, max_doc_length)\n",
    "        self.reldict = load_rel(rel_file)\n",
    "        self.qids = sorted(list(self.reldict.keys()))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.qids)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        qid = self.qids[item]\n",
    "        pid = random.choice(self.reldict[qid])\n",
    "        query_data = self.query_dataset[qid]\n",
    "        passage_data = self.doc_dataset[pid]\n",
    "        return query_data, passage_data\n",
    "\n",
    "\n",
    "class TrainInbatchWithHardDataset(TrainInbatchDataset):\n",
    "    def __init__(self, rel_file, rank_file, queryids_cache, \n",
    "            docids_cache, hard_num,\n",
    "            max_query_length, max_doc_length):\n",
    "        TrainInbatchDataset.__init__(self, \n",
    "            rel_file, queryids_cache, docids_cache, \n",
    "            max_query_length, max_doc_length)\n",
    "        self.rankdict = json.load(open(rank_file))\n",
    "        assert hard_num > 0\n",
    "        self.hard_num = hard_num\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.qids)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        qid = self.qids[item]\n",
    "        pid = random.choice(self.reldict[qid])\n",
    "        query_data = self.query_dataset[qid]\n",
    "        passage_data = self.doc_dataset[pid]\n",
    "        hardpids = random.sample(self.rankdict[str(qid)], self.hard_num)\n",
    "        hard_passage_data = [self.doc_dataset[hardpid] for hardpid in hardpids]\n",
    "        return query_data, passage_data, hard_passage_data\n",
    "\n",
    "\n",
    "class TrainInbatchWithRandDataset(TrainInbatchDataset):\n",
    "    def __init__(self, rel_file, queryids_cache, \n",
    "            docids_cache, rand_num,\n",
    "            max_query_length, max_doc_length):\n",
    "        TrainInbatchDataset.__init__(self, \n",
    "            rel_file, queryids_cache, docids_cache, \n",
    "            max_query_length, max_doc_length)\n",
    "        assert rand_num > 0\n",
    "        self.rand_num = rand_num\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        qid = self.qids[item]\n",
    "        pid = random.choice(self.reldict[qid])\n",
    "        query_data = self.query_dataset[qid]\n",
    "        passage_data = self.doc_dataset[pid]\n",
    "        randpids = random.sample(range(len(self.doc_dataset)), self.rand_num)\n",
    "        rand_passage_data = [self.doc_dataset[randpid] for randpid in randpids]\n",
    "        return query_data, passage_data, rand_passage_data\n",
    "\n",
    "\n",
    "def single_get_collate_function(max_seq_length, padding=False):\n",
    "    cnt = 0\n",
    "    def collate_function(batch):\n",
    "        nonlocal cnt\n",
    "        length = None\n",
    "        if cnt < 10 or padding:\n",
    "            length = max_seq_length\n",
    "            cnt += 1\n",
    "\n",
    "        input_ids = [x[\"input_ids\"] for x in batch]\n",
    "        attention_mask = [x[\"attention_mask\"] for x in batch]\n",
    "        data = {\n",
    "            \"input_ids\": pack_tensor_2D(input_ids, default=1, \n",
    "                dtype=torch.int64, length=length),\n",
    "            \"attention_mask\": pack_tensor_2D(attention_mask, default=0, \n",
    "                dtype=torch.int64, length=length),\n",
    "        }\n",
    "        ids = [x['id'] for x in batch]\n",
    "        return data, ids\n",
    "    return collate_function  \n",
    "\n",
    "\n",
    "def dual_get_collate_function(max_query_length, max_doc_length, rel_dict, padding=False):\n",
    "    query_collate_func = single_get_collate_function(max_query_length, padding)\n",
    "    doc_collate_func = single_get_collate_function(max_doc_length, padding)\n",
    "\n",
    "    def collate_function(batch):\n",
    "        query_data, query_ids = query_collate_func([x[0] for x  in batch])\n",
    "        doc_data, doc_ids = doc_collate_func([x[1] for x in batch])\n",
    "        rel_pair_mask = [[1 if docid not in rel_dict[qid] else 0 \n",
    "            for docid in doc_ids]\n",
    "            for qid in query_ids]\n",
    "        input_data = {\n",
    "            \"input_query_ids\":query_data['input_ids'],\n",
    "            \"query_attention_mask\":query_data['attention_mask'],\n",
    "            \"input_doc_ids\":doc_data['input_ids'],\n",
    "            \"doc_attention_mask\":doc_data['attention_mask'],\n",
    "            \"rel_pair_mask\":torch.FloatTensor(rel_pair_mask),\n",
    "            }\n",
    "        return input_data\n",
    "    return collate_function  \n",
    "\n",
    "\n",
    "def triple_get_collate_function(max_query_length, max_doc_length, rel_dict, padding=False):\n",
    "    query_collate_func = single_get_collate_function(max_query_length, padding)\n",
    "    doc_collate_func = single_get_collate_function(max_doc_length, padding)\n",
    "\n",
    "    def collate_function(batch):\n",
    "        query_data, query_ids = query_collate_func([x[0] for x  in batch])\n",
    "        doc_data, doc_ids = doc_collate_func([x[1] for x in batch])\n",
    "        hard_doc_data, hard_doc_ids = doc_collate_func(sum([x[2] for x in batch], []))\n",
    "        rel_pair_mask = [[1 if docid not in rel_dict[qid] else 0 \n",
    "            for docid in doc_ids]\n",
    "            for qid in query_ids]\n",
    "        hard_pair_mask = [[1 if docid not in rel_dict[qid] else 0 \n",
    "            for docid in hard_doc_ids ]\n",
    "            for qid in query_ids]\n",
    "        query_num = len(query_data['input_ids'])\n",
    "        hard_num_per_query = len(batch[0][2])\n",
    "        input_data = {\n",
    "            \"input_query_ids\":query_data['input_ids'],\n",
    "            \"query_attention_mask\":query_data['attention_mask'],\n",
    "            \"input_doc_ids\":doc_data['input_ids'],\n",
    "            \"doc_attention_mask\":doc_data['attention_mask'],\n",
    "            \"other_doc_ids\":hard_doc_data['input_ids'].reshape(query_num, hard_num_per_query, -1),\n",
    "            \"other_doc_attention_mask\":hard_doc_data['attention_mask'].reshape(query_num, hard_num_per_query, -1),\n",
    "            \"rel_pair_mask\":torch.FloatTensor(rel_pair_mask),\n",
    "            \"hard_pair_mask\":torch.FloatTensor(hard_pair_mask),\n",
    "            }\n",
    "        return input_data\n",
    "    return collate_function  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a92815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T17:03:18.822587Z",
     "iopub.status.busy": "2024-05-31T17:03:18.822303Z",
     "iopub.status.idle": "2024-05-31T17:03:18.962360Z",
     "shell.execute_reply": "2024-05-31T17:03:18.961657Z"
    },
    "papermill": {
     "duration": 0.150821,
     "end_time": "2024-05-31T17:03:18.964489",
     "exception": false,
     "start_time": "2024-05-31T17:03:18.813668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += ['./']\n",
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "def index_retrieve(index, query_embeddings, topk, batch=None):\n",
    "    print(\"Query Num\", len(query_embeddings))\n",
    "    start = timer()\n",
    "    if batch is None:\n",
    "        _, nearest_neighbors = index.search(query_embeddings, topk)\n",
    "    else:\n",
    "        query_offset_base = 0\n",
    "        pbar = tqdm(total=len(query_embeddings))\n",
    "        nearest_neighbors = []\n",
    "        while query_offset_base < len(query_embeddings):\n",
    "            batch_query_embeddings = query_embeddings[query_offset_base:query_offset_base+ batch]\n",
    "            batch_nn = index.search(batch_query_embeddings, topk)[1]\n",
    "            nearest_neighbors.extend(batch_nn.tolist())\n",
    "            query_offset_base += len(batch_query_embeddings)\n",
    "            pbar.update(len(batch_query_embeddings))\n",
    "        pbar.close()\n",
    "\n",
    "    elapsed_time = timer() - start\n",
    "    elapsed_time_per_query = 1000 * elapsed_time / len(query_embeddings)\n",
    "    print(f\"Elapsed Time: {elapsed_time:.1f}s, Elapsed Time per query: {elapsed_time_per_query:.1f}ms\")\n",
    "    return nearest_neighbors\n",
    "\n",
    "\n",
    "\n",
    "def construct_flatindex_from_embeddings(embeddings, ids=None):\n",
    "    dim = embeddings.shape[1]\n",
    "    print('embedding shape: ' + str(embeddings.shape))\n",
    "    index = faiss.index_factory(dim, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "    if ids is not None:\n",
    "        ids = ids.astype(np.int64)\n",
    "        print(ids.shape, ids.dtype)\n",
    "        index = faiss.IndexIDMap2(index)\n",
    "        index.add_with_ids(embeddings, ids)\n",
    "    else:\n",
    "        index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "\n",
    "gpu_resources = []\n",
    "\n",
    "def convert_index_to_gpu(index, faiss_gpu_index, useFloat16=False):\n",
    "    if type(faiss_gpu_index) == list and len(faiss_gpu_index) == 1:\n",
    "        faiss_gpu_index = faiss_gpu_index[0]\n",
    "    if isinstance(faiss_gpu_index, int):\n",
    "        res = faiss.StandardGpuResources()\n",
    "        res.setTempMemory(512*1024*1024)\n",
    "        co = faiss.GpuClonerOptions()\n",
    "        co.useFloat16 = useFloat16\n",
    "        index = faiss.index_cpu_to_gpu(res, faiss_gpu_index, index, co)\n",
    "    else:\n",
    "        global gpu_resources\n",
    "        if len(gpu_resources) == 0:\n",
    "            import torch\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                res = faiss.StandardGpuResources()\n",
    "                res.setTempMemory(256*1024*1024)\n",
    "                gpu_resources.append(res)\n",
    "\n",
    "        assert isinstance(faiss_gpu_index, list)\n",
    "        vres = faiss.GpuResourcesVector()\n",
    "        vdev = faiss.IntVector()\n",
    "        co = faiss.GpuMultipleClonerOptions()\n",
    "        co.shard = True\n",
    "        co.useFloat16 = useFloat16\n",
    "        for i in faiss_gpu_index:\n",
    "            vdev.push_back(i)\n",
    "            vres.push_back(gpu_resources[i])\n",
    "        index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)\n",
    "\n",
    "    return index\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b77822df",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-31T17:03:18.980793Z",
     "iopub.status.busy": "2024-05-31T17:03:18.980506Z",
     "iopub.status.idle": "2024-05-31T17:03:19.000328Z",
     "shell.execute_reply": "2024-05-31T17:03:18.999452Z"
    },
    "papermill": {
     "duration": 0.030286,
     "end_time": "2024-05-31T17:03:19.002214",
     "exception": false,
     "start_time": "2024-05-31T17:03:18.971928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import subprocess\n",
    "import sys\n",
    "sys.path.append(\"./\")\n",
    "import faiss\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import RobertaConfig\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "logger = logging.Logger(__name__)\n",
    "\n",
    "\n",
    "def prediction(model, data_collator, args, test_dataset, embedding_memmap, ids_memmap, is_query):\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        sampler=SequentialSampler(test_dataset),\n",
    "        batch_size=args.eval_batch_size*args.n_gpu,\n",
    "        collate_fn=data_collator,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    # multi-gpu eval\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    batch_size = test_dataloader.batch_size\n",
    "    num_examples = len(test_dataloader.dataset)\n",
    "    logger.info(\"***** Running *****\")\n",
    "    logger.info(\"  Num examples = %d\", num_examples)\n",
    "    logger.info(\"  Batch size = %d\", batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    write_index = 0\n",
    "    for step, (inputs, ids) in enumerate(tqdm(test_dataloader)):\n",
    "        for k, v in inputs.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(args.device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(is_query=is_query, **inputs).detach().cpu().numpy()\n",
    "        write_size = len(logits)\n",
    "        assert write_size == len(ids)\n",
    "        embedding_memmap[write_index:write_index+write_size] = logits\n",
    "        ids_memmap[write_index:write_index+write_size] = ids\n",
    "        write_index += write_size\n",
    "    assert write_index == len(embedding_memmap) == len(ids_memmap)\n",
    "\n",
    "\n",
    "def query_inference(model, args, embedding_size):\n",
    "    if os.path.exists(args.query_memmap_path):\n",
    "        print(f\"{args.query_memmap_path} exists, skip inference\")\n",
    "        return\n",
    "    query_collator = single_get_collate_function(args.max_query_length)\n",
    "    query_dataset = SequenceDataset(\n",
    "        ids_cache=TextTokenIdsCache(data_dir=args.preprocess_dir, prefix=\"queries\"),\n",
    "        max_seq_length=args.max_query_length\n",
    "    )\n",
    "    query_memmap = np.memmap(args.query_memmap_path, \n",
    "        dtype=np.float32, mode=\"w+\", shape=(len(query_dataset), embedding_size))\n",
    "    queryids_memmap = np.memmap(args.queryids_memmap_path, \n",
    "        dtype=np.int32, mode=\"w+\", shape=(len(query_dataset), ))\n",
    "    try:\n",
    "        prediction(model, query_collator, args,\n",
    "                query_dataset, query_memmap, queryids_memmap, is_query=True)\n",
    "    except:\n",
    "        subprocess.check_call([\"rm\", args.query_memmap_path])\n",
    "        subprocess.check_call([\"rm\", args.queryids_memmap_path])\n",
    "        raise\n",
    "\n",
    "\n",
    "def doc_inference(model, args, embedding_size):\n",
    "    if os.path.exists(args.doc_memmap_path):\n",
    "        print(f\"{args.doc_memmap_path} exists, skip inference\")\n",
    "        return\n",
    "    doc_collator = single_get_collate_function(args.max_doc_length)\n",
    "    ids_cache = TextTokenIdsCache(data_dir=args.preprocess_dir, prefix=\"passages\")\n",
    "    subset=list(range(len(ids_cache)))\n",
    "    doc_dataset = SubsetSeqDataset(\n",
    "        subset=subset,\n",
    "        ids_cache=ids_cache,\n",
    "        max_seq_length=args.max_doc_length\n",
    "    )\n",
    "    assert not os.path.exists(args.doc_memmap_path)\n",
    "    doc_memmap = np.memmap(args.doc_memmap_path, \n",
    "        dtype=np.float32, mode=\"w+\", shape=(len(doc_dataset), embedding_size))\n",
    "    docid_memmap = np.memmap(args.docid_memmap_path, \n",
    "        dtype=np.int32, mode=\"w+\", shape=(len(doc_dataset), ))\n",
    "    try:\n",
    "        prediction(model, doc_collator, args,\n",
    "            doc_dataset, doc_memmap, docid_memmap, is_query=False\n",
    "        )\n",
    "    except:\n",
    "        subprocess.check_call([\"rm\", args.doc_memmap_path])\n",
    "        subprocess.check_call([\"rm\", args.docid_memmap_path])\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc3fc803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T17:03:19.017667Z",
     "iopub.status.busy": "2024-05-31T17:03:19.017403Z",
     "iopub.status.idle": "2024-05-31T19:09:47.404999Z",
     "shell.execute_reply": "2024-05-31T19:09:47.404014Z"
    },
    "papermill": {
     "duration": 7589.232265,
     "end_time": "2024-05-31T19:09:48.241647",
     "exception": false,
     "start_time": "2024-05-31T17:03:19.009382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mean: False\n",
      "output_embedding_size 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:01<00:00, 21.76it/s]\n",
      "100%|██████████| 17607/17607 [2:06:20<00:00,  2.32it/s]\n"
     ]
    }
   ],
   "source": [
    "### MAIN ###\n",
    "\n",
    "args = Namespace(\n",
    "    data_type = \"doc\",\n",
    "    max_query_length = 32,\n",
    "    max_doc_length = 512,\n",
    "    eval_batch_size = 32,\n",
    "    mode = \"dev\",\n",
    "    topk = 100,\n",
    "    no_cuda = False,\n",
    "    faiss_gpus = None\n",
    ")\n",
    "\n",
    "\n",
    "args.device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "args.n_gpu = torch.cuda.device_count()\n",
    "\n",
    "args.preprocess_dir = f\"/kaggle/input/adore-preprocess/data/{args.data_type}/preprocess\"\n",
    "args.model_path = \"/kaggle/input/star-pretrained\"\n",
    "args.output_dir = \"/kaggle/working/{args.data_type}/evaluate/star\"\n",
    "args.query_memmap_path = os.path.join(args.output_dir, f\"{args.mode}-query.memmap\")\n",
    "args.queryids_memmap_path = os.path.join(args.output_dir, f\"{args.mode}-query-id.memmap\")\n",
    "args.output_rank_file = os.path.join(args.output_dir, f\"{args.mode}.rank.tsv\")\n",
    "args.doc_memmap_path = os.path.join(args.output_dir, \"passages.memmap\")\n",
    "args.docid_memmap_path = os.path.join(args.output_dir, \"passages-id.memmap\")\n",
    "logger.info(args)\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "config = RobertaConfig.from_pretrained(args.model_path, gradient_checkpointing=False)\n",
    "model = RobertaDot.from_pretrained(args.model_path, config=config)\n",
    "output_embedding_size = model.output_embedding_size\n",
    "\n",
    "model = model.to(args.device)\n",
    "\n",
    "query_inference(model, args, output_embedding_size)\n",
    "doc_inference(model, args, output_embedding_size)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5116242,
     "sourceId": 8559822,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 180797472,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30715,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7622.34827,
   "end_time": "2024-05-31T19:09:50.959327",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-31T17:02:48.611057",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
