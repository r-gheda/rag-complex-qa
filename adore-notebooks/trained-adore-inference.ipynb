{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "602ff3d2",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-06-02T21:25:13.196324Z",
     "iopub.status.busy": "2024-06-02T21:25:13.195610Z",
     "iopub.status.idle": "2024-06-02T21:25:33.468676Z",
     "shell.execute_reply": "2024-06-02T21:25:33.467749Z"
    },
    "papermill": {
     "duration": 20.280324,
     "end_time": "2024-06-02T21:25:33.470987",
     "exception": false,
     "start_time": "2024-06-02T21:25:13.190663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\r\n",
      "Collecting faiss-gpu\r\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.15.1)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (1.26.100)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.4.0)\r\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.51.1)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.26.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.5.2)\r\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (69.0.3)\r\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.16.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.0.2)\r\n",
      "Collecting botocore<1.30.0,>=1.29.100 (from boto3)\r\n",
      "  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3) (0.6.2)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3) (2.9.0.post0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3) (1.26.18)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\r\n",
      "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: faiss-gpu, botocore\r\n",
      "  Attempting uninstall: botocore\r\n",
      "    Found existing installation: botocore 1.34.69\r\n",
      "    Uninstalling botocore-1.34.69:\r\n",
      "      Successfully uninstalled botocore-1.34.69\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "aiobotocore 2.12.3 requires botocore<1.34.70,>=1.34.41, but you have botocore 1.29.165 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed botocore-1.29.165 faiss-gpu-1.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers faiss-gpu tensorboard boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f2bd1d9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-02T21:25:33.486446Z",
     "iopub.status.busy": "2024-06-02T21:25:33.486138Z",
     "iopub.status.idle": "2024-06-02T21:25:40.002001Z",
     "shell.execute_reply": "2024-06-02T21:25:40.001008Z"
    },
    "papermill": {
     "duration": 6.526491,
     "end_time": "2024-06-02T21:25:40.004433",
     "exception": false,
     "start_time": "2024-06-02T21:25:33.477942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from torch._C import dtype\n",
    "sys.path += ['./']\n",
    "import torch\n",
    "from torch import nn\n",
    "import transformers\n",
    "if int(transformers.__version__[0]) <=3:\n",
    "    from transformers.modeling_roberta import RobertaPreTrainedModel\n",
    "else:\n",
    "    from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "from transformers import RobertaModel\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "class EmbeddingMixin:\n",
    "    \"\"\"\n",
    "    Mixin for common functions in most embedding models. Each model should define its own bert-like backbone and forward.\n",
    "    We inherit from RobertaModel to use from_pretrained \n",
    "    \"\"\"\n",
    "    def __init__(self, model_argobj):\n",
    "        if model_argobj is None:\n",
    "            self.use_mean = False\n",
    "        else:\n",
    "            self.use_mean = model_argobj.use_mean\n",
    "        print(\"Using mean:\", self.use_mean)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding, nn.Conv1d)):\n",
    "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
    "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "\n",
    "    def masked_mean(self, t, mask):\n",
    "        s = torch.sum(t * mask.unsqueeze(-1).float(), axis=1)\n",
    "        d = mask.sum(axis=1, keepdim=True).float()\n",
    "        return s / d\n",
    "\n",
    "    def masked_mean_or_first(self, emb_all, mask):\n",
    "        # emb_all is a tuple from bert - sequence output, pooler\n",
    "        assert isinstance(emb_all, tuple)\n",
    "        if self.use_mean:\n",
    "            return self.masked_mean(emb_all[0], mask)\n",
    "        else:\n",
    "            return emb_all[0][:, 0]\n",
    "\n",
    "    def query_emb(self, input_ids, attention_mask):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "    def body_emb(self, input_ids, attention_mask):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "\n",
    "class BaseModelDot(EmbeddingMixin):\n",
    "    def _text_encode(self, input_ids, attention_mask):\n",
    "        # TODO should raise NotImplementedError\n",
    "        # temporarily do this  \n",
    "        return None \n",
    "\n",
    "    def query_emb(self, input_ids, attention_mask):\n",
    "        outputs1 = self._text_encode(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "        full_emb = self.masked_mean_or_first(outputs1, attention_mask)\n",
    "        query1 = self.norm(self.embeddingHead(full_emb))\n",
    "        return query1\n",
    "\n",
    "    def body_emb(self, input_ids, attention_mask):\n",
    "        return self.query_emb(input_ids, attention_mask)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, is_query, *args):\n",
    "        assert len(args) == 0\n",
    "        if is_query:\n",
    "            return self.query_emb(input_ids, attention_mask)\n",
    "        else:\n",
    "            return self.body_emb(input_ids, attention_mask)\n",
    "\n",
    "        \n",
    "class RobertaDot(BaseModelDot, RobertaPreTrainedModel):\n",
    "    def __init__(self, config, model_argobj=None):\n",
    "        BaseModelDot.__init__(self, model_argobj)\n",
    "        RobertaPreTrainedModel.__init__(self, config)\n",
    "        if int(transformers.__version__[0]) ==4 :\n",
    "            config.return_dict = False\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        if hasattr(config, \"output_embedding_size\"):\n",
    "            self.output_embedding_size = config.output_embedding_size\n",
    "        else:\n",
    "            self.output_embedding_size = config.hidden_size\n",
    "        print(\"output_embedding_size\", self.output_embedding_size)\n",
    "        self.embeddingHead = nn.Linear(config.hidden_size, self.output_embedding_size)\n",
    "        self.norm = nn.LayerNorm(self.output_embedding_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _text_encode(self, input_ids, attention_mask):\n",
    "        outputs1 = self.roberta(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "        return outputs1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416d61a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:25:40.019718Z",
     "iopub.status.busy": "2024-06-02T21:25:40.019295Z",
     "iopub.status.idle": "2024-06-02T21:25:40.037846Z",
     "shell.execute_reply": "2024-06-02T21:25:40.036948Z"
    },
    "papermill": {
     "duration": 0.028241,
     "end_time": "2024-06-02T21:25:40.039673",
     "exception": false,
     "start_time": "2024-06-02T21:25:40.011432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += [\"./\"]\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset\n",
    "from typing import List\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class TextTokenIdsCache:\n",
    "    def __init__(self, data_dir, prefix):\n",
    "        meta = json.load(open(f\"{data_dir}/{prefix}_meta\"))\n",
    "        self.total_number = meta['total_number']\n",
    "        self.max_seq_len = meta['embedding_size']\n",
    "        try:\n",
    "            self.ids_arr = np.memmap(f\"{data_dir}/{prefix}.memmap\", \n",
    "                shape=(self.total_number, self.max_seq_len), \n",
    "                dtype=np.dtype(meta['type']), mode=\"r\")\n",
    "            self.lengths_arr = np.load(f\"{data_dir}/{prefix}_length.npy\")\n",
    "        except FileNotFoundError:\n",
    "            self.ids_arr = np.memmap(f\"{data_dir}/memmap/{prefix}.memmap\", \n",
    "                shape=(self.total_number, self.max_seq_len), \n",
    "                dtype=np.dtype(meta['type']), mode=\"r\")\n",
    "            self.lengths_arr = np.load(f\"{data_dir}/memmap/{prefix}_length.npy\")\n",
    "        assert len(self.lengths_arr) == self.total_number\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.total_number\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return self.ids_arr[item, :self.lengths_arr[item]]\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, ids_cache, max_seq_length):\n",
    "        self.ids_cache = ids_cache\n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "    def __len__(self):  \n",
    "        return len(self.ids_cache)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        input_ids = self.ids_cache[item].tolist()\n",
    "        seq_length = min(self.max_seq_length-1, len(input_ids)-1)\n",
    "        input_ids = [input_ids[0]] + input_ids[1:seq_length] + [input_ids[-1]]\n",
    "        attention_mask = [1]*len(input_ids)\n",
    "\n",
    "        ret_val = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"id\": item,\n",
    "        }\n",
    "        return ret_val\n",
    "    \n",
    "\n",
    "\n",
    "def pack_tensor_2D(lstlst, default, dtype, length=None):\n",
    "    batch_size = len(lstlst)\n",
    "    length = length if length is not None else max(len(l) for l in lstlst)\n",
    "    tensor = default * torch.ones((batch_size, length), dtype=dtype)\n",
    "    for i, l in enumerate(lstlst):\n",
    "        tensor[i, :len(l)] = torch.tensor(l, dtype=dtype)\n",
    "    return tensor\n",
    "\n",
    "    \n",
    "    \n",
    "def get_collate_function(max_seq_length):\n",
    "    cnt = 0\n",
    "    def collate_function(batch):\n",
    "        nonlocal cnt\n",
    "        length = None\n",
    "        if cnt < 10:\n",
    "            length = max_seq_length\n",
    "            cnt += 1\n",
    "\n",
    "        input_ids = [x[\"input_ids\"] for x in batch]\n",
    "        attention_mask = [x[\"attention_mask\"] for x in batch]\n",
    "        data = {\n",
    "            \"input_ids\": pack_tensor_2D(input_ids, default=1, \n",
    "                dtype=torch.int64, length=length),\n",
    "            \"attention_mask\": pack_tensor_2D(attention_mask, default=0, \n",
    "                dtype=torch.int64, length=length),\n",
    "        }\n",
    "        ids = [x['id'] for x in batch]\n",
    "        return data, ids\n",
    "    return collate_function  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e81e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:25:40.054194Z",
     "iopub.status.busy": "2024-06-02T21:25:40.053942Z",
     "iopub.status.idle": "2024-06-02T21:25:40.191142Z",
     "shell.execute_reply": "2024-06-02T21:25:40.190454Z"
    },
    "papermill": {
     "duration": 0.146886,
     "end_time": "2024-06-02T21:25:40.193191",
     "exception": false,
     "start_time": "2024-06-02T21:25:40.046305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += ['./']\n",
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "def index_retrieve(index, query_embeddings, topk, batch=None):\n",
    "    print(\"Query Num\", len(query_embeddings))\n",
    "    start = timer()\n",
    "    if batch is None:\n",
    "        _, nearest_neighbors = index.search(query_embeddings, topk)\n",
    "    else:\n",
    "        query_offset_base = 0\n",
    "        pbar = tqdm(total=len(query_embeddings))\n",
    "        nearest_neighbors = []\n",
    "        while query_offset_base < len(query_embeddings):\n",
    "            batch_query_embeddings = query_embeddings[query_offset_base:query_offset_base+ batch]\n",
    "            batch_nn = index.search(batch_query_embeddings, topk)[1]\n",
    "            nearest_neighbors.extend(batch_nn.tolist())\n",
    "            query_offset_base += len(batch_query_embeddings)\n",
    "            pbar.update(len(batch_query_embeddings))\n",
    "        pbar.close()\n",
    "\n",
    "    elapsed_time = timer() - start\n",
    "    elapsed_time_per_query = 1000 * elapsed_time / len(query_embeddings)\n",
    "    print(f\"Elapsed Time: {elapsed_time:.1f}s, Elapsed Time per query: {elapsed_time_per_query:.1f}ms\")\n",
    "    return nearest_neighbors\n",
    "\n",
    "\n",
    "\n",
    "def construct_flatindex_from_embeddings(embeddings, ids=None):\n",
    "    dim = embeddings.shape[1]\n",
    "    print('embedding shape: ' + str(embeddings.shape))\n",
    "    index = faiss.index_factory(dim, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "    if ids is not None:\n",
    "        ids = ids.astype(np.int64)\n",
    "        print(ids.shape, ids.dtype)\n",
    "        index = faiss.IndexIDMap2(index)\n",
    "        index.add_with_ids(embeddings, ids)\n",
    "    else:\n",
    "        index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "\n",
    "gpu_resources = []\n",
    "\n",
    "def convert_index_to_gpu(index, faiss_gpu_index, useFloat16=False):\n",
    "    if type(faiss_gpu_index) == list and len(faiss_gpu_index) == 1:\n",
    "        faiss_gpu_index = faiss_gpu_index[0]\n",
    "    if isinstance(faiss_gpu_index, int):\n",
    "        res = faiss.StandardGpuResources()\n",
    "        res.setTempMemory(512*1024*1024)\n",
    "        co = faiss.GpuClonerOptions()\n",
    "        co.useFloat16 = useFloat16\n",
    "        index = faiss.index_cpu_to_gpu(res, faiss_gpu_index, index, co)\n",
    "    else:\n",
    "        global gpu_resources\n",
    "        if len(gpu_resources) == 0:\n",
    "            import torch\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                res = faiss.StandardGpuResources()\n",
    "                res.setTempMemory(256*1024*1024)\n",
    "                gpu_resources.append(res)\n",
    "\n",
    "        assert isinstance(faiss_gpu_index, list)\n",
    "        vres = faiss.GpuResourcesVector()\n",
    "        vdev = faiss.IntVector()\n",
    "        co = faiss.GpuMultipleClonerOptions()\n",
    "        co.shard = True\n",
    "        co.useFloat16 = useFloat16\n",
    "        for i in faiss_gpu_index:\n",
    "            vdev.push_back(i)\n",
    "            vres.push_back(gpu_resources[i])\n",
    "        index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)\n",
    "\n",
    "    return index\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f678b255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:25:40.207777Z",
     "iopub.status.busy": "2024-06-02T21:25:40.207497Z",
     "iopub.status.idle": "2024-06-02T21:25:40.218184Z",
     "shell.execute_reply": "2024-06-02T21:25:40.217534Z"
    },
    "papermill": {
     "duration": 0.020094,
     "end_time": "2024-06-02T21:25:40.220055",
     "exception": false,
     "start_time": "2024-06-02T21:25:40.199961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += [\"./\"]\n",
    "import os\n",
    "import torch\n",
    "import faiss\n",
    "import logging\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import RobertaConfig\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format = '%(asctime)s-%(levelname)s-%(name)s- %(message)s',\n",
    "                        datefmt = '%d %H:%M:%S',\n",
    "                        level = logging.INFO)\n",
    "\n",
    "\n",
    "def evaluate(args, model):\n",
    "    \"\"\" Train the model \"\"\"    \n",
    "    dev_dataset = SequenceDataset(\n",
    "            TextTokenIdsCache(args.preprocess_dir, f\"queries\"), \n",
    "            args.max_seq_length)\n",
    "    collate_fn = get_collate_function(args.max_seq_length)\n",
    "    batch_size = args.pergpu_eval_batch_size\n",
    "    if args.n_gpu > 1:\n",
    "        batch_size *= args.n_gpu\n",
    "    dev_dataloader = DataLoader(dev_dataset, \n",
    "        batch_size= batch_size, collate_fn=collate_fn)\n",
    "\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    qembedding_memmap = np.memmap(args.qmemmap_path, dtype=\"float32\",\n",
    "        shape=(len(dev_dataset), 768), mode=\"w+\")\n",
    "    with torch.no_grad():\n",
    "        for step, (batch, qoffsets) in enumerate(tqdm(dev_dataloader)):\n",
    "            batch = {k:v.to(args.model_device) for k, v in batch.items()}\n",
    "            model.eval()            \n",
    "            embeddings = model(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"], \n",
    "                is_query=True)\n",
    "            embeddings = embeddings.detach().cpu().numpy()\n",
    "            qembedding_memmap[qoffsets] = embeddings\n",
    "    return qembedding_memmap\n",
    "\n",
    "\n",
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa0aeccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:25:40.234466Z",
     "iopub.status.busy": "2024-06-02T21:25:40.234182Z",
     "iopub.status.idle": "2024-06-02T21:27:00.110898Z",
     "shell.execute_reply": "2024-06-02T21:27:00.109978Z"
    },
    "papermill": {
     "duration": 79.886481,
     "end_time": "2024-06-02T21:27:00.113082",
     "exception": false,
     "start_time": "2024-06-02T21:25:40.226601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mean: False\n",
      "output_embedding_size 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:02<00:00, 18.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding shape: (563424, 768)\n",
      "Query Num 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:52<00:00, 23.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 52.0s, Elapsed Time per query: 43.3ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = Namespace(\n",
    "    model_dir = \"/kaggle/input/adore-training/out/epoch-6/\",\n",
    "    output_dir = \"/kaggle/working/\",\n",
    "    preprocess_dir = \"/kaggle/input/adore-preprocess/data/doc/preprocess\",\n",
    "    mode = \"dev\",\n",
    "    topk = 100,\n",
    "    dmemmap_path = \"/kaggle/input/star-inference/{args.data_type}/evaluate/star/passages.memmap\",\n",
    "    max_seq_length = 64,\n",
    "    pergpu_eval_batch_size = 32,\n",
    "    no_cuda = False,\n",
    "    faiss_gpus = None   \n",
    ")\n",
    "\n",
    "assert os.path.exists(args.dmemmap_path)\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "# Setup CUDA, GPU \n",
    "args.use_gpu = torch.cuda.is_available() and not args.no_cuda\n",
    "args.model_device = torch.device(f\"cuda:0\" if args.use_gpu else \"cpu\")\n",
    "args.n_gpu = 1\n",
    "\n",
    "# Setup logging\n",
    "logger.warning(\"Model Device: %s, n_gpu: %s\", args.model_device, args.n_gpu)\n",
    "config = RobertaConfig.from_pretrained(args.model_dir)\n",
    "model = RobertaDot.from_pretrained(args.model_dir, config=config)\n",
    "    \n",
    "model.to(args.model_device)\n",
    "logger.info(\"Training/evaluation parameters %s\", args)\n",
    "# Evaluation\n",
    "args.qmemmap_path = f\"{args.output_dir}/{args.mode}.qembed.memmap\"\n",
    "evaluate(args, model)\n",
    "\n",
    "doc_embeddings = np.memmap(args.dmemmap_path, \n",
    "    dtype=np.float32, mode=\"r\").reshape(-1, model.output_embedding_size)\n",
    "\n",
    "query_embeddings = np.memmap(args.qmemmap_path, \n",
    "    dtype=np.float32, mode=\"r\").reshape(-1, model.output_embedding_size)\n",
    "model = None\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "index = construct_flatindex_from_embeddings(doc_embeddings, None)\n",
    "if args.faiss_gpus:\n",
    "    index = convert_index_to_gpu(index, args.faiss_gpus, False)\n",
    "else:\n",
    "    faiss.omp_set_num_threads(32)\n",
    "nearest_neighbors = index_retrieve(index, query_embeddings, args.topk, batch=32)\n",
    "output_rank_file = os.path.join(args.output_dir, f\"{args.mode}.rank.tsv\")\n",
    "with open(output_rank_file, 'w') as outputfile:\n",
    "    for qid, neighbors in enumerate(nearest_neighbors):\n",
    "        for idx, pid in enumerate(neighbors):\n",
    "            outputfile.write(f\"{qid}\\t{pid}\\t{idx+1}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5057969,
     "sourceId": 8480287,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5116227,
     "sourceId": 8559804,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5116242,
     "sourceId": 8559822,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 180801020,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 181071682,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 181118823,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 111.158955,
   "end_time": "2024-06-02T21:27:01.646917",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-02T21:25:10.487962",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
